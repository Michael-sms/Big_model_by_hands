{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "本章涵盖以下内容：\n",
    "\n",
    "+ **计算训练集和验证集的损失，以评估训练过程中大型语言模型生成文本的质量**\n",
    "+ **实现训练函数并预训练大语言模型**\n",
    "+ **保存和加载模型权重以便继续训练大语言模型**\n",
    "+ **从OpenAI加载预训练权重**\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "- [5.1 生成式文本模型的评估](#51-生成式文本模型的评估)\n",
    "  - [5.1.1 使用 GPT 生成文本](#511-使用-gpt-生成文本)\n",
    "  - [5.1.2 文本生成损失的计算](#512-文本生成损失的计算)\n",
    "  - [5.1.3 计算训练集和验证集的损失](#513-计算训练集和验证集的损失)\n",
    "- [5.2 训练 LLM](#52-训练-llm)\n",
    "- [5.3 通过解码策略控制生成结果的随机性](#53-通过解码策略控制生成结果的随机性)\n",
    "  - [5.3.1 Temperature scaling](#531-temperature-scaling)\n",
    "  - [5.3.2 Top-k 采样](#532-top-k-采样)\n",
    "  - [5.3.3 对文本生成函数进行调整](#533-对文本生成函数进行调整)\n",
    "- [5.4 在 PyTorch 中加载和保存模型权重](#54-在-pytorch-中加载和保存模型权重)\n",
    "- [5.5 从 OpenAI 加载预训练权重](#55-从-openai-加载预训练权重)\n",
    "- [5.6 本章摘要](#56-本章摘要)\n",
    "\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "\n",
    "在之前的章节中，我们实现了数据采样、注意力机制，并编写了 LLM 的架构。本章的核心是实现训练函数并对 LLM 进行预训练，详见图 5.1。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.1.png\" width=\"75%\" />\n",
    "\n",
    "如图5.1所示，我们将继续学习基本的模型评估技术，以衡量生成文本的质量，这对于在训练过程中优化 LLM 是非常必要的。此外，我们将讨论如何加载预训练权重，以便为接下来的微调提供坚实的基础。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **权重参数**\n",
    ">\n",
    "> 在大语言模型（LLM）和其他深度学习模型中，权重指的是可以通过训练过程调整的参数，通常也被称为权重参数或直接称为参数。在 PyTorch 等框架中，这些权重通常存储在各层（如线性层）中，举例来说，我们在第 3 章实现的多头注意力模块和第 4 章实现的GPT模型中就使用了线性层。在初始化一个层（例如，`new_layer = torch.nn.Linear(...)`）后，我们可以通过`.weight`属性访问其权重，例如`new_layer.weight`。此外，出于便利性，PyTorch还允许通过`model.parameters()`方法直接访问模型的所有可训练参数，包括权重和偏置，我们将在后续实现模型训练时使用该方法。\n"
   ],
   "id": "1c6351ba66f968da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.1 生成式文本模型的评估\n",
    "\n",
    "本章开篇，我们将基于上一章的代码设置 LLM 进行文本生成，并讨论如何对生成文本质量进行评估的基本方法。而本章剩余部分的内容请参考图5.2。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.2.png\" width=\"75%\" />\n",
    "\n",
    "如图 5.2 所示，接下来的小节我们首先简要回顾上一章末尾的文本生成过程，然后深入探讨文本评估及训练和验证损失的计算方法。\n",
    "\n",
    "\n",
    "\n",
    "### 5.1.1 使用 GPT 生成文本\n",
    "\n",
    "在本节中，我们会先通过对 LLM 的设置简要回顾一下第四章中实现的文本生成过程。在开始这项工作之前，我们首先使用第 4 章中的 GPTModel 类和 GPT_CONFIG_124M 配置字典初始化 GPT 模型，以便在后续章节对其进行评估和训练：\n"
   ],
   "id": "32d50910acc5e1a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:48.666777400Z",
     "start_time": "2026-01-13T13:30:43.577129300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,        #A\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,             #B\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "\n",
    "#A 我们将上下文长度从1024个token缩短到256个token\n",
    "#B 将 dropout 设置为 0 是一种常见的做法"
   ],
   "id": "a38c0f0e2bf0996d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在之前定义的 GPT_CONFIG_124M 配置字典中，我们唯一的调整是将上下文长度（context_length）减少到 256 个 token。此项调整降低了模型训练的计算需求，使得可以在普通笔记本电脑上进行训练。\n",
    "\n",
    "参数量为 1.24 亿的 GPT-2 模型最初被配置为可处理最多 1024 个 token。本章结束时，我们将更新上下文大小设置，并加载预训练权重，使模型能够支持 1024-token 的上下文长度。\n",
    "\n",
    "我们通过前一章节中介绍的 generate_text_simple 函数来使用 GPTmodel 实例，同时引入了两个实用函数：text_to_token_ids 和token_ids_to_text。这些函数简化了文本与 token 表示之间的转换，本章中我们将多次使用这种技术。图 5.3 可以帮助我们更清楚地理解这一过程。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.3.png\" width=\"75%\" />\n",
    "\n",
    "图 5.3 展示了使用 GPT 模型生成文本的三个主要步骤。首先，分词器将输入文本转换为一系列 token ID（在第 2 章中已有讨论）。然后，模型接收这些 token ID 并生成对应的 logits（即词汇表中每个 token 的概率分布，具体见第 4 章）。最后，将 logits 转换回 token ID，分词器将其解码为可读的文本，完成从文本输入到文本输出的循环。\n",
    "\n",
    "我们通过代码来实现上述过程："
   ],
   "id": "65377833f39dd00b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:49.359426900Z",
     "start_time": "2026-01-13T13:30:48.675801800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Listing 5.1 Utility functions for text to token ID conversion\n",
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "611f3a623a82ba7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "执行代码，模型生成的文本如下：\n",
    "\n",
    "```\n",
    "Output text:\n",
    " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n",
    "```\n",
    "\n",
    "从输出可以看出，模型尚未生成连贯的文本，因为它还没有经过训练。为了定义文本的‘连贯性’或‘高质量’，我们需要实现一种数值方法来评估生成的内容。这一方法将帮助我们在训练过程中监督并提升模型的性能。\n",
    "\n",
    "接下来将介绍如何计算生成内容的损失度量，该损失值会作为训练进展和效果的指示器。此外，在后续关于微调 LLM 的章节中，我们将探讨更多评估模型质量的方法。\n"
   ],
   "id": "385bc5a90964c1ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.1.2 文本生成损失的计算\n",
    "\n",
    "本节将探讨如何通过计算‘文本生成损失’来数值化评估训练过程中生成的文本质量。在通过一个实际示例逐步讲解这一主题之前，先简要回顾第 2 章的数据加载方式以及第 4 章的`generate_text_simple`函数如何生成文本。\n",
    "\n",
    "图 5.4 展示了从输入文本到 LLM 生成文本的整体流程，该流程通过五个步骤实现。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.4.png\" width=\"75%\" />\n",
    "\n",
    "图 5.4 展示了第 4 章中`generate_text_simple`函数内部的本生成过程。在后续章节中计算生成文本的质量损失之前，我们需要先执行这些初始步骤。\n",
    "\n",
    "为了便于在一页中展示图像，我们图中的示例仅使用了包含 7 个 token 的小型词汇表。然而，GPTModel 实际上使用了包含 50,257 个 token 的大型词汇表，因此在接下来的代码中，token ID 的范围为 0 到 50,256，而不是图示中的 0 到 6。\n",
    "\n",
    "此外，图 5.4 为了简洁仅展示了一个文本示例 'every effort moves'。在接下来的代码示例中，我们将实现图 5.4 中的步骤，并使用两个输入示例 'every effort moves' 和 'I really like' 作为 GPT 模型的输入。\n",
    "\n",
    "考虑两个输入样本，它们已经被转换为 token ID，对应图 5.4 中的步骤 1：\n"
   ],
   "id": "14c206823571a59b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:49.414765200Z",
     "start_time": "2026-01-13T13:30:49.364929900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    "                       [40, 1107, 588]])    # \"I really like\"]\n",
    "# Matching these inputs, the `targets` contain the token IDs we aim for the model to produce:\n",
    "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
    "                        [107, 588, 11311]]) # \" really like chocolate\"]"
   ],
   "id": "7f55586a1125ab69",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "需要注意的是，目标值中展示的是输入数据向前偏移了一个位置。我们在第 2 章实现数据加载器时已介绍过这一概念。这种偏移策略对于教会模型预测序列中的下一个 token 至关重要。\n",
    "\n",
    "接着我们将两个输入示例（每个示例样本包含三个 token）输入模型以计算它们的 logit 向量，再应用 Softmax 函数将这些 logit 值转换为概率得分，这对应于图 5.4 中的步骤 2：\n"
   ],
   "id": "32531054b92c5c25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:49.499196600Z",
     "start_time": "2026-01-13T13:30:49.417276800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ],
   "id": "6dc901cf3505a195",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "生成的概率得分张量（probas）的维度如下：\n",
    "\n",
    "```\n",
    "torch.Size([2, 3, 50257])\n",
    "```\n",
    "\n",
    "第一个数字 2 表示输入中的两个样本（行），即批次大小。第二个数字 3 表示每个样本包含的 token 数量。最后一个数字表示嵌入维度的大小，通常由词汇表大小决定，前面章节已讨论。\n",
    "\n",
    "通过 softmax 函数将 logits 转换为概率后，第 4 章的 generate_text_simple 函数会将概率得分进一步转换回文本，这一过程在图 5.4 的步骤 3 到步骤 5 中进行了展示。\n",
    "\n",
    "接下来，通过对概率得分应用 `argmax` 函数，可以得到对应的 token ID（实现步骤 3 和 步骤 4）：\n"
   ],
   "id": "a1ea4335cd63b048"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:49.570306400Z",
     "start_time": "2026-01-13T13:30:49.503195100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\",token_ids)"
   ],
   "id": "aff26caae837bae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "假设我们有 2 个输入样本，每个样本包含 3 个 token。在对概率得分应用 argmax 函数后（对应图 5.4 的第 3 步），会得到 2 组输出，每组包含 3 个预测的 token ID：\n",
    "\n",
    "```\n",
    "Token IDs:\n",
    "tensor([[[16657], # First batch\n",
    "        [ 339],\n",
    "        [42826]],\n",
    "\n",
    "       [[49906],  # Second batch\n",
    "        [29669],\n",
    "        [41751]]])\n",
    "```\n",
    "\n",
    "最后，步骤 5 将 token ID 转换回文本：\n"
   ],
   "id": "5c4c8b1835505835"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:49.644679500Z",
     "start_time": "2026-01-13T13:30:49.582816800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "#When we decode these tokens, we find that these output tokens are quite different from the target tokens we want the model to generate:"
   ],
   "id": "5e535e87d39ac8ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "可以看到，模型生成的文本与目标文本不同，因为它尚未经过训练。接下来，我们将通过‘损失’来数值化评估模型生成文本的质量（详见图 5.5）。这不仅有助于衡量生成文本的质量，还为实现训练函数提供了基础，训练函数主要通过更新模型权重来改善生成文本的质量。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.5.png\" width=\"75%\" />\n",
    "\n",
    "文本评估过程的一部分（如图 5.5 所示）是衡量生成的 token 与正确预测目标之间的差距。本章后面实现的训练函数将利用这些信息来调整模型权重，使生成的文本更接近（或理想情况下完全匹配）目标文本。\n",
    "\n",
    "换句话说，模型训练的目标是提高正确目标 token ID 所在位置的 softmax 概率，如图 5.6 所示。接下来的部分中，我们还会将该 softmax 概率作为评价指标，用于对模型生成的输出进行数值化评估：正确位置上的概率越高，模型效果越好。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.6.png\" width=\"75%\" />\n",
    "\n",
    "请注意，图 5.6 使用了一个包含 7 个 token 的简化词汇表，以便所有内容可以在一张图中展示。这意味着 softmax 的初始随机值会在 1/7 左右（约 0.14）。\n",
    "\n",
    "然而，我们为 GPT-2 模型使用的词汇表包含 50,257 个 token，因此每个 token 的初始概率大约只有 0.00002（即 1/50,257）。\n",
    "\n",
    "对于这两个输入文本，我们可以通过以下代码打印与目标 token 对应的初始 softmax 概率得分：\n"
   ],
   "id": "d94124933fc1ab3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:49.717299800Z",
     "start_time": "2026-01-13T13:30:49.649684100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ],
   "id": "ffa9963e38bda91d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([3.9108e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "每个批次中 3 个目标 token ID 的概率如下：\n",
    "\n",
    "```\n",
    "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
    "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n",
    "```\n",
    "\n",
    "训练 LLM 的目标就是最大化这些概率值，使其尽量接近 1。这样可以确保 LLM 始终选择目标 token —— 即句中的下一个词，作为生成的下一个 token。"
   ],
   "id": "5072b6d95ce69ffe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> [!NOTE]\n",
    ">\n",
    "> **反向传播**\n",
    ">\n",
    "> 如何最大化目标 token 的 softmax 概率值？整体思路是通过更新模型权重，使模型在生成目标 token 时输出更高的概率值。权重更新通过一种称为反向传播的过程来实现，这是一种训练深度神经网络的标准技术（关于反向传播和模型训练的更多细节可见附录 A 的 A.3 至 A.7 节）。\n",
    ">\n",
    "> 反向传播需要一个损失函数，该函数用于计算模型预测输出与实际目标输出之间的差异（此处指与目标 token ID 对应的概率）。这个损失函数用于衡量模型预测与目标值的偏差程度。\n",
    "\n",
    "在本节剩余内容中，我们将针对`target_probas_1`和`target_probas_2`的概率得分计算损失。图 5.7 展示了主要步骤。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.7.png\" width=\"75%\" />\n",
    "\n",
    "由于我们已经完成了图 5.7 中列出的步骤 1-3，得到了 `target_probas_1` 和 `target_probas_2`，现在进行第 4 步，对这些概率得分取对数：\n"
   ],
   "id": "be8b4c460a35b3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:49.772097700Z",
     "start_time": "2026-01-13T13:30:49.721831100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "log_probas =torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(\"Log-probabilities:\", log_probas)"
   ],
   "id": "7f0090c4621a730d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-probabilities: tensor([ -9.5042, -10.3796, -11.3677, -10.1492,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "计算结果如下：\n",
    "\n",
    "```\n",
    "tensor([ -9.5042, -10.3796, -11.3677, -11.4798, -9.7764, -12.2561])\n",
    "```\n",
    "\n",
    "在数学优化中，处理概率得分的对数比直接处理概率得分更为简便。该主题超出本书的讨论范围，但我在一个讲座中对此进行了详细讲解，链接位于附录 B 的参考部分。\n",
    "> [!TIP]\n",
    ">\n",
    "> **个人思考：** 在继续接下来的计算之前，我们首先来探讨一下，对数在损失函数的应用中到底有什么作用。\n",
    ">\n",
    "> 1. **为什么要用概率的对数**\n",
    ">\n",
    ">    在 LLM 中，概率得分通常是小于1的数（例如0.1、0.05等），直接用这些数进行计算和优化可能会面临一些问题。比如，如果多个概率相乘，结果会变得非常小，甚至接近0。这种情况称为“数值下溢”（Numerical Underflow），可能导致计算不稳定。\n",
    ">\n",
    ">    假设我们有三个概率值，分别为0.2、0.1和0.05。如果我们计算这些值的乘积，结果是：\n",
    ">\n",
    ">    $$0.2×0.1×0.05=0.001$$\n",
    ">\n",
    ">    这个值非常小，尤其在深度学习或概率模型中，我们通常会有成千上万个概率需要相乘，这样会导致最终的乘积接近0甚至为0，造成数值计算的不稳定性。\n",
    ">\n",
    ">    如果我们对这些概率值取对数，然后相加，而不是直接相乘，我们可以避免这个问题。例如，对这三个值取自然对数（logarithm）后再相加：\n",
    ">\n",
    ">    $$ln(0.2)+ln(0.1)+ln(0.05)≈−1.6094+(−2.3026)+(−2.9957)=−6.9077$$\n",
    ">\n",
    ">    虽然这个和也是负数，但它不会像直接相乘的结果那样接近于0，避免了数值下溢的问题。**对数的累加性质**允许我们将原本的累乘操作转换为累加，使得计算更加稳定和高效。\n",
    ">\n",
    ">\n",
    ">\n",
    "> 2. 对数概率在损失函数中的作用**\n",
    ">\n",
    ">    GPT模型训练的目标是最大化正确目标 token 的概率，通常，我们会使用交叉熵损失来衡量模型预测与实际目标之间的差异。对于一个目标 token 序列 y=(y1,y2,…,yn)，GPT会生成一个对应的预测概率分布 P(y∣x)，其中 x 是模型的输入。\n",
    ">\n",
    ">    **交叉熵损失的公式：**\n",
    ">\n",
    ">    在计算交叉熵损失时，我们希望最大化模型分配给每个正确目标token的概率。交叉熵损失的数学公式为：\n",
    ">\n",
    ">    $$\\text { Loss }=-\\sum_{t=1}^{T} \\ln P\\left(y_{t} \\mid x, \\theta\\right)$$\n",
    ">\n",
    ">    其中：\n",
    ">\n",
    ">    + T 是序列长度\n",
    ">    + y<sub>t</sub> 是在位置 ttt 上的目标token\n",
    ">    + P(y<sub>t</sub>∣x,θ) 是模型在参数 θ 下对目标token y<sub>t</sub>  的条件概率\n",
    ">\n",
    ">    在公式中，对每个token的概率 P(y<sub>t</sub>∣x,θ)  取对数，将乘积形式的联合概率转换为求和形式，有助于避免数值下溢，同时简化优化过程。\n"
   ],
   "id": "494c0b50495cc949"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "接下来，通过计算平均值将这些对数概率合并为一个评分（参见图 5.7 的第 5 步）：",
   "id": "6579c4a1d6aa21cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:49.924869600Z",
     "start_time": "2026-01-13T13:30:49.778655100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ],
   "id": "af35283e6e9b06e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.5722)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "由此生成的平均对数概率评分如下：\n",
    "\n",
    "```\n",
    "tensor(-10.5722)\n",
    "```\n",
    "\n",
    "训练的目标就是通过更新模型权重，使平均对数概率尽可能接近 0（将在 5.2 节中实现）。\n",
    "\n",
    "然而，在深度学习中，常见做法并不是直接将平均对数概率推向 0，而是通过将负平均对数概率降低至 0 来实现。负平均对数概率就是平均对数概率乘以 -1，这与图 5.7 的第 6 步相对应：\n"
   ],
   "id": "a260aca28b0febfc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:49.989632100Z",
     "start_time": "2026-01-13T13:30:49.933491400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ],
   "id": "60c78892d69a13f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5722)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "结算的结果为：`tensor(10.5722)`。\n",
    "\n",
    "这种将负值 -10.5722 转化为正值 10.5722 的操作在深度学习中称为交叉熵损失。\n",
    "\n",
    "在这里，PyTorch 非常实用，因为它内置的 cross_entropy 函数已经自动处理了图 5.7 中的 6 个步骤。"
   ],
   "id": "fecf92b6b61acdb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> [!NOTE]\n",
    ">\n",
    "> **交叉熵损失**\n",
    ">\n",
    "> 本质上，交叉熵损失是在机器学习和深度学习中一种常用的度量方法，用于衡量两个概率分布之间的差异——通常是标签的真实分布（此处为数据集中的 token）和模型的预测分布（例如，LLM 生成的 token 概率）。\n",
    ">\n",
    "> 在机器学习，特别是 PyTorch 等框架中，cross_entropy 函数用于计算离散输出的损失，与模型生成的 token 概率下的目标 token 的负平均对数概率类似。因此，cross entropy 和负平均对数概率这两个术语在计算上有关联，实践中经常互换使用。\n",
    "\n",
    "在应用交叉熵函数之前，我们先简要回顾一下 logits 和目标张量的形状：\n"
   ],
   "id": "b59d290c66057265"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:50.053688200Z",
     "start_time": "2026-01-13T13:30:50.001652900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ],
   "id": "3aeee94bcddea975",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "可以看到，logits 是个三维张量（批量大小、token 数量和词汇表大小）。而 targets 是个二维张量（批量大小和 token 数量）。\n",
    "\n",
    "在 PyTorch 中使用交叉熵损失函数时，我们需要将这些张量展平，以便在批量维度上进行合并："
   ],
   "id": "307f38f60d110a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:50.125534Z",
     "start_time": "2026-01-13T13:30:50.066415300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits_flat =logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Logits flat shape:\", logits_flat.shape)\n",
    "print(\"Targets flat shape:\", targets_flat.shape)"
   ],
   "id": "ad45f386ce86b63f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits flat shape: torch.Size([6, 50257])\n",
      "Targets flat shape: torch.Size([6])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "得到的张量维度如下：\n",
    "\n",
    "```\n",
    "Flattened logits: torch.Size([6, 50257])\n",
    "Flattened targets: torch.Size([6])\n",
    "```\n",
    "\n",
    "请记住，targets 是希望 LLM 生成的目标 token ID，而 logits 包含了在进入 softmax 函数之前的模型原始输出。\n",
    "\n",
    "我们之前的实现是先应用 Softmax 函数，再选择目标 token ID 对应的概率分数，计算负的平均对数概率。而在 PyTorch 中，`cross_entropy` 函数能够自动完成所有这些步骤："
   ],
   "id": "80d5238e22940625"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:50.228436800Z",
     "start_time": "2026-01-13T13:30:50.133532900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss =torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ],
   "id": "6b457d1dafa5e1b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5722)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "计算得到的损失值与之前手动执行图 5.7 中各个步骤时获得的结果相同：\n",
    "\n",
    "```\n",
    "tensor(10.7940)\n",
    "```\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **Perplexity**\n",
    ">\n",
    "> `Perplexity` 是一种经常与交叉熵损失一起使用的指标，用于评估语言建模等任务中的模型表现。它能够以更具可解释性的方式，帮助理解模型在预测下一个 token 时的不确定性。\n",
    ">\n",
    "> `Perplexity` 常用于衡量模型预测的概率分布与数据集中词的实际分布的接近程度。类似于损失函数，`Perplexity`的值越低，表示模型预测越接近真实分布。\n",
    ">\n",
    "> `Perplexity`可通过 `perplexity = torch.exp(loss)` 计算，对先前计算的损失值应用此公式将返回 `tensor(48725.8203)`。\n",
    ">\n",
    "> `Perplexity`通常比原始损失值更具可解释性，因为它表示了模型在每一步生成中，对有效词汇量的不确定程度。在这个例子中，`Perplexity`可以理解为模型在词汇表中的 47,678 个单词或 token 中，不确定该选择哪个作为下一个生成的 token。\n",
    "\n",
    "在本节中，我们对两个小文本输入进行了损失计算，以便更直观地说明损失函数的计算过程。下一节将把损失计算应用于整个训练集和验证集。\n"
   ],
   "id": "d14c463c58d11dbf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.1.3 计算训练集和验证集的损失\n",
    "\n",
    "在本节中，我们首先准备训练和验证数据集，以用于后续 LLM 的训练。接着，我们计算训练集和验证集的交叉熵（如图 5.8 所示），这是模型训练过程中的重要组成部分。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.8.png\" width=\"75%\" />\n",
    "\n",
    "为了计算训练集和验证集上的损失（如图 5.8 所示），我们使用了一个非常小的文本数据集，即伊迪丝·华顿的短篇小说《判决》，我们在第 2 章中已对此文本进行过处理。选择公共领域的文本可以避免任何关于使用权的担忧。此外，我们选择小数据集的原因在于，它允许代码示例在普通笔记本电脑上运行，即使没有高端 GPU 也能在几分钟内完成，这对于教学尤为有利。\n",
    "\n",
    "感兴趣的读者可以使用本书的配套代码，准备一个包含超过 60,000 本 Project Gutenberg 公有领域书籍的大规模数据集，并在此数据集上训练 LLM（详情请见附录 D）。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **预训练 LLM 的成本**\n",
    ">\n",
    "> 为了更好地理解项目的规模，以一个相对受欢迎的开源 LLM - 70 亿参数的 Llama 2 模型的训练为例。该模型的训练在昂贵的 A100 GPU 上共耗费了 184,320 个小时，处理了 2 万亿个 token。在撰写本文时，AWS 上 8 张 A100 卡的云服务器每小时费用约为 30 美元。粗略估算，训练这样一个 LLM 的总成本约为 69 万美元（计算方法为 184,320 小时除以 8，再乘以 30 美元）。\n",
    "\n",
    "以下代码用于加载我们在第 2 章中使用的《判决》短篇小说：\n"
   ],
   "id": "d32bcbbdbf7eb1bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:50.276669300Z",
     "start_time": "2026-01-13T13:30:50.237466200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = \"../data/the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ],
   "id": "42318f2f93b90e6b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "加载数据集后，我们可以查看其中的字符数和 token 数：",
   "id": "40f25fd612e9ef45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:50.429497700Z",
     "start_time": "2026-01-13T13:30:50.285175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Total characters:\", total_characters)\n",
    "print(\"Total tokens:\", total_tokens)"
   ],
   "id": "c8b8e226197d9667",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 20479\n",
      "Total tokens: 5145\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "输出如下：\n",
    "\n",
    "```\n",
    "Characters: 20479\n",
    "Tokens: 5145\n",
    "```\n",
    "\n",
    "仅有 5,145 个 token，看起来似乎不足以训练一个 LLM，但正如前面提到的，这仅用于教学演示，因此我们可以将代码的运行时间控制在几分钟，而不是几周。此外，在本章最后，我们将把 OpenAI 的预训练权重加载到我们的 GPTModel 代码中。\n",
    "\n",
    "接下来，我们将数据集划分为训练集和验证集，并使用第二章的数据加载器为 LLM 训练准备需输入的批量数据。图 5.9 展示了该过程。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.9.png\" width=\"75%\" />\n",
    "\n",
    "出于可视化的需要，图 5.9 将最大长度设置为 6。然而，在实际数据加载器中，我们会将最大长度设置为 LLM 支持的 256 个 token 的上下文长度，使得模型在训练时可以看到更长的文本。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **处理变长输入的训练**\n",
    ">\n",
    "> 在训练模型时，我们可以使用大小相似的数据块来保证训练过程的简便和高效。然而，在实践中，使用变长的输入进行训练往往有助于提升 LLM 的泛化能力，使其在应用时能够适应不同类型的输入。\n",
    "\n",
    "为了实现图 5.9 中的数据划分与加载，我们首先定义一个 `train_ratio`，用于将 90% 的数据用于训练，剩余 10% 用于在训练期间进行模型评估：\n"
   ],
   "id": "d45f30ccb4a77732"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:50.484433100Z",
     "start_time": "2026-01-13T13:30:50.459638200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(len(text_data) * train_ratio)\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ],
   "id": "d092de5ea7b8b888",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "现在可以使用 train_data 和 val_data 子集，复用第 2 章中的 create_dataloader_v1 代码来创建相应的数据加载器:",
   "id": "5136400b74e6aaa8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:50.531745500Z",
     "start_time": "2026-01-13T13:30:50.497587800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ],
   "id": "59e9526337ab3534",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在前面的代码示例中，由于数据集较小，我们使用了较小的批量以降低计算资源的消耗。实际训练 LLM 时，批量大小达到 1,024 或更高并不少见。\n",
    "\n",
    "为了确认数据加载器是否正确创建，可以通过遍历这些数据加载器来检查："
   ],
   "id": "41d3031f41d911c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:50.584654600Z",
     "start_time": "2026-01-13T13:30:50.532743900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train data:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nVal data:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ],
   "id": "664fc00f263e1c8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Val data:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "执行代码，可以看到以下输出：\n",
    "\n",
    "```\n",
    "Train loader:\n",
    "torch.Size([2, 256]) torch.Size([2, 256])\n",
    "torch.Size([2, 256]) torch.Size([2, 256])\n",
    "torch.Size([2, 256]) torch.Size([2, 256])\n",
    "torch.Size([2, 256]) torch.Size([2, 256])\n",
    "torch.Size([2, 256]) torch.Size([2, 256])\n",
    "torch.Size([2, 256]) torch.Size([2, 256])\n",
    "torch.Size([2, 256]) torch.Size([2, 256])\n",
    "torch.Size([2, 256]) torch.Size([2, 256])\n",
    "torch.Size([2, 256]) torch.Size([2, 256])\n",
    "\n",
    "Validation loader:\n",
    "torch.Size([2, 256]) torch.Size([2, 256])\n",
    "```\n",
    "\n",
    "可以看到，训练集中共有 9 个批次，每批包含 2 个样本，每个样本有 256 个 token。由于只分配了 10% 的数据用于验证，因此验证集中只有 1 个批次，包含 2 个样本。\n",
    "\n",
    "和我们的预期一致，输入数据（x）和目标数据（y）的形状相同（即批次大小 × 每批的 token 数量），因为目标数据是将输入数据整体向后偏移一个位置得到的，正如第 2 章讨论的那样。\n",
    "\n",
    "接下来我们实现一个工具函数，用于计算由训练和验证加载器返回的批量数据的交叉熵损失：\n"
   ],
   "id": "7eda7a474239274c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:50.636194100Z",
     "start_time": "2026-01-13T13:30:50.600041500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)       #A\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "#A 将数据传输到指定设备（如 GPU），使数据能够在 GPU 上处理。"
   ],
   "id": "c861c26639d9550d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "现在我们可以使用 `calc_loss_batch` 工具函数来实现 `calc_loss_loader` 函数，`calc_loss_loader` 将用于计算指定数据加载器中的指定数据批次的损失:",
   "id": "6162f616d4b8bcd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:50.670458100Z",
     "start_time": "2026-01-13T13:30:50.637198400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Listing 5.2 Function to compute the training and validation loss\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)                                    #A\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))                  #B\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()                                     #C\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches                                       #D\n",
    "\n",
    "\n",
    "#A 如果没有指定批次数，将自动遍历所有批次\n",
    "#B 若批次数超过数据加载器的总批次数，则减少批次数使其与数据加载器的批次数相匹配\n",
    "#C 每个批次的损失求和\n",
    "#D 对所有批次的损失取平均值"
   ],
   "id": "e16fabe819bcf9ad",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "默认情况下，`calc_loss_batch` 函数会遍历 `data loader` 中的所有批次数据，将每批次的损失累加到 `total_loss` 中，并计算所有批次的平均损失。作为替代方案，我们可以通过 `num_batches` 参数指定更少的批次数，以加快模型训练过程中的评估速度。\n",
    "\n",
    "现在让我们看看如何将 `calc_loss_batch` 函数应用到训练集和验证集加载器中："
   ],
   "id": "7ae60d408e8dae50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:55.595158200Z",
     "start_time": "2026-01-13T13:30:50.672459300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ],
   "id": "9506a11f0ab4b56a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583584255642\n",
      "Validation loss: 10.981106758117676\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "损失值如下：\n",
    "```\n",
    "Training loss: 10.98758347829183\n",
    "Validation loss: 10.98110580444336\n",
    "```\n",
    "\n",
    "模型未经过训练，因此损失值较高。相比之下，如果模型学会按训练集和验证集中的真实顺序生成下一个 token，损失值就会接近 0。\n",
    "\n",
    "现在我们已经有了评估生成文本质量的方法，接下来我们将训练 LLM 以减少损失，从而提升文本生成的效果，如图 5.10 所示。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.10.png\" width=\"75%\" />\n",
    "\n",
    "如图 5.10 所示，下一节将重点讲解 LLM 的预训练过程。在模型训练完成后，将应用不同的文本生成策略，并保存和加载预训练模型的权重。"
   ],
   "id": "2334540deeafc914"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.2 训练 LLM\n",
    "\n",
    "在本节中，我们将实现 LLM（基于GPTModel）的预训练代码。我们重点采用一种简单的训练循环方式来保证代码简洁易读（如图 5.11 所示）。不过，有兴趣的读者可以在附录 D 中了解更多高级技术，包括学习率预热、余弦退火和梯度裁剪等，以进一步完善训练循环。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.11.png\" width=\"75%\" />\n",
    "\n",
    "图 5.11 中的流程图展示了一个典型的 PyTorch 神经网络训练流程，我们用它来训练大语言模型（LLM）。流程概述了 8 个步骤，从迭代各个 epoch 开始，处理批次数据、重置和计算梯度、更新权重，最后进行监控步骤如打印损失和生成文本样本。如果你对使用 PyTorch 如何训练深度神经网络不太熟悉，可以参考附录 A 中的 A.5 至 A.8 节。\n",
    "\n",
    "我们可以通过以下`train_model_simple`函数来实现这一训练流程："
   ],
   "id": "25e7fee46c395ef4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:55.632055900Z",
     "start_time": "2026-01-13T13:30:55.596161800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Listing 5.3 The main function for pretraining LLMs\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []                        #A\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):                                                 #B\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()                                                   #C\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()                                                         #D\n",
    "            optimizer.step()                                                        #E\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:                                        #F\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        generate_and_print_sample(                                                  #G\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "#A 初始化用于记录损失和已处理 token 数量的列表\n",
    "#B 开始主训练循环\n",
    "#C 重置上一批次的损失梯度\n",
    "#D 计算损失梯度\n",
    "#E 使用损失梯度更新模型权重\n",
    "#F 可选的评估步骤\n",
    "#G 每个 epoch 结束后打印示例文本"
   ],
   "id": "7703e29ea8da3bdc",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "注意，我们刚刚创建的 `train_model_simple` 函数使用了两个尚未定义的函数：`evaluate_model` 和 `generate_and_print_sample`。\n",
    "\n",
    "`evaluate_model` 函数对应图 5.11 中的步骤 7。该函数会在每次模型更新后打印训练集和验证集的损失，从而帮助我们评估训练是否改进了模型。\n",
    "\n",
    "更具体地说，`evaluate_model` 函数会在训练集和验证集上计算损失，同时确保模型处于评估模式，并在计算损失时禁用梯度跟踪和 dropout"
   ],
   "id": "9db740b42bef9bef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:55.674785400Z",
     "start_time": "2026-01-13T13:30:55.633055600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ],
   "id": "504a79a84f485609",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "与 `evaluate_model` 类似，`generate_and_print_sample` 是一个工具函数，用于跟踪模型在训练过程中是否有改进。具体来说，`generate_and_print_sample` 函数接收一个文本片段（`start_context`）作为输入，将其转换为 token ID，并传递给 LLM，借助之前的 `generate_text_simple` 函数生成文本示例：",
   "id": "6d0d7006decea762"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:30:55.718737300Z",
     "start_time": "2026-01-13T13:30:55.676795800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size =model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \")) # Compact print format\n",
    "    model.train()"
   ],
   "id": "45d3189f850f9846",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`evaluate_model`函数通过数值来评估模型的训练进展，而`generate_and_print_sample`函数则通过生成的实际文本示例，帮助我们在训练过程中判断模型的能力。\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> **ADAMW**\n",
    ">\n",
    "> Adam 优化器在深度神经网络训练中非常流行。然而在我们的训练循环中，我们选择了 AdamW 优化器。AdamW 是 Adam 的一种变体，通过改进权重衰减方式，帮助减少模型复杂度，并通过惩罚较大的权重来防止过拟合。这样的调整使得 AdamW 能更有效地实现正则化，并提升模型的泛化能力，因此被广泛应用于大语言模型的训练中。\n",
    "\n",
    "让我们通过训练一个 GPTModel 实例来实际操作看看，训练 10 个 epoch，使用 AdamW 优化器和之前定义的`train_model_simple`函数："
   ],
   "id": "3e6d9205061fe92d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:32.808333600Z",
     "start_time": "2026-01-13T13:30:55.722737100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=1,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ],
   "id": "a7e88973a782e55b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.897, Val loss 9.933\n",
      "Ep 1 (Step 000005): Train loss 7.917, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.847, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 5.997, Val loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.659, Val loss 6.600\n",
      "Ep 3 (Step 000025): Train loss 5.363, Val loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.010, Val loss 6.278\n",
      "Ep 4 (Step 000035): Train loss 2.549, Val loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.834, Val loss 6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.516, Val loss 6.179\n",
      "Ep 6 (Step 000050): Train loss 3.006, Val loss 6.141\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.575, Val loss 6.134\n",
      "Ep 7 (Step 000060): Train loss 1.757, Val loss 6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 0.958, Val loss 6.238\n",
      "Ep 8 (Step 000070): Train loss 1.497, Val loss 6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.796, Val loss 6.293\n",
      "Ep 9 (Step 000080): Train loss 0.639, Val loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.404, Val loss 6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "执行 `training_model_simple` 函数将开始训练过程，在 MacBook Air 或类似的笔记本电脑上完成约需 5 分钟。执行过程中打印的输出如下所示：\n",
    "\n",
    "```\n",
    "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
    "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
    "Every effort moves you,,,,,,,,,,,,.\n",
    "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
    "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
    "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and,\n",
    "and, and, and, and, and, and, and, and, and,, and, and,\n",
    "[...] Results are truncated to save space                 #A\n",
    "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.393\n",
    "Every effort moves you?\" \"Yes--quite insensible to the irony. She wanted him\n",
    "vindicated--and by me!\" He laughed again, and threw back the window-curtains, I had the\n",
    "donkey. \"There were days when I\n",
    "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
    "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and\n",
    "silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run\n",
    "over from Monte Carlo; and Mrs. Gis\n",
    "\n",
    "#A 中间结果被省略以节省空间\n",
    "```\n",
    "\n",
    "根据训练过程中的输出结果，训练损失显著下降，从 9.781 降到 0.391，模型的语言能力大幅提升。在训练初期，模型仅能在起始上下文后添加逗号（如“Every effort moves you,,,,,,,,,,,,”）或重复单词“and”。而在训练结束时，模型能够生成符合语法的文本。\n",
    "\n",
    "与训练集损失类似，我们可以看到验证集损失在开始时较高（9.933），随后在训练过程中下降。但它始终未能像训练集损失那样低，在第 10 个 epoch 后保持在 6.452。\n",
    "\n",
    "在更详细地讨论验证集损失之前，我们先创建一个简单的图表，将训练集和验证集损失并排展示："
   ],
   "id": "712b45e062e31445"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:33.396672700Z",
     "start_time": "2026-01-13T13:35:32.811351100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny() #A\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) #B\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "\n",
    "#A 创建与 y 轴共用的第二个 x 轴\n",
    "#B 用于对齐刻度的隐藏图形"
   ],
   "id": "b2161d9b03f928e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "生成的训练损失和验证损失图表如图 5.12 所示。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.12.png\" width=\"75%\" />\n",
    "\n",
    "如图 5.12 所示，训练损失和验证损失在第一个 epoch 开始时都有所改善。然而，从第二个 epoch 之后，损失开始出现分歧。验证损失远高于训练损失，这表明模型在训练数据上出现了过拟合。我们可以通过搜索生成的文本片段（例如“The Verdict”文件中的片段：“quite insensible to the irony”）来确认模型逐词记住了训练数据。\n",
    "\n",
    "这种记忆现象是预料之中的，因为我们使用了一个非常小的训练数据集，并且对模型进行了多轮训练。通常，我们会在更大的数据集上训练模型，并且只需训练一个 epoch 即可。\n",
    "\n",
    "> [!TIP]\n",
    ">\n",
    "> **个人思考：** 让我们基于 LLM 的原理来探讨一下为什么在一个较小的数据集上进行多轮训练，容易产生过拟合的现象？\n",
    ">\n",
    "> 1. **模型容量与数据集大小的匹配问题**\n",
    ">    + 大语言模型具有极高的参数容量，通常包含数百万甚至数十亿个参数。如此巨大的参数空间可以高度灵活地适应数据，使得模型能够“记住”每个样本的具体特征\n",
    ">    + 当数据集很小时，模型没有足够的多样性去学习广泛的模式，而是倾向于学习每个数据点的细节。经过多轮训练，模型会逐渐“记住”小数据集中每个样本的特征，从而导致过拟合。\n",
    "> 2. **多轮训练导致对数据集细节的过度学习**\n",
    ">    + 多轮训练意味着模型会反复接触相同的数据。这种重复使得模型逐渐适应数据集的特定模式，而不是学习一般化的规律。\n",
    ">    + 每次训练迭代都会使模型在数据集上拟合得更好，因此在训练数据上损失逐渐减小，但由于缺少新的数据，模型无法学习到通用模式，只会进一步记住训练样本的细节。\n",
    "> 3. **数据集的多样性不足**\n",
    ">    + 小数据集通常不能代表广泛的语言特征和分布，缺乏多样性。模型在小数据集上多轮训练，基本上是在有限的样本范围内形成模式，导致它对特定的训练样本依赖性过强。\n",
    ">    + 这种缺乏多样性的训练会使模型偏向训练数据的分布，难以适应实际应用中广泛的输入数据。\n",
    "> 4. **过拟合与模型泛化能力的矛盾**\n",
    ">    + 过拟合本质上是模型在训练数据上的表现优异，但在未见过的数据上表现较差。大语言模型的训练目标是提高其泛化能力，即能在更广泛的分布上生成有意义的文本。\n",
    ">    + 当数据集非常小且多轮训练时，模型会对数据的细节和噪声进行过度拟合，这会导致模型在测试数据或实际应用中表现不佳，因为它无法应对新的、不同分布的输入。\n",
    ">\n",
    ">\n"
   ],
   "id": "6650809bb5a3eb52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在接下来的部分（如图 5.13 所示），我们将探讨 LLM 使用的采样方法，这些方法可以减轻记忆效应，从而生成更具新意的文本。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.13.png\" width=\"75%\" />\n",
    "\n",
    "如图 5.13 所示，下一节将介绍适用于 LLM 的文本生成策略，以减少训练数据的记忆倾向，提升 LLM 生成文本的原创性。之后我们还会讨论权重的加载与保存，以及从 OpenAI 的 GPT 模型加载预训练权重。"
   ],
   "id": "6a5b292e585f59a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.3 通过解码策略控制生成结果的随机性\n",
    "\n",
    "本节将介绍文本生成策略（也称为解码策略），用于生成更具原创性的文本。首先，我们将简要回顾前一章中的`generate_text_simple`函数，该函数已在本章前面用于生成和打印样本。然后，我们会讲解两种改进方法：`temperature scaling`和 `top-k 采样`。\n",
    "\n",
    "首先，我们将模型从 GPU 转移回 CPU，因为相对较小的模型在推理时不需要使用 GPU。另外，在训练结束后，我们会将模型切换到评估模式，以关闭 dropout 等随机组件："
   ],
   "id": "977c07e98fdc65b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:33.461502800Z",
     "start_time": "2026-01-13T13:35:33.402967700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ],
   "id": "d09a2f62c7e2738",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "接下来，将 GPTModel 的实例（model）传入 generate_text_simple 函数，该函数使用 LLM 一次生成一个 token：",
   "id": "72e4c935d7e2a558"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:34.523386800Z",
     "start_time": "2026-01-13T13:35:33.462504200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "59655af0e147fe30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "执行代码，会生成以下文本：\n",
    "\n",
    "```\n",
    "Output text:\n",
    "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and\n",
    "silver of an exquisitely appointed lun\n",
    "```\n",
    "\n",
    "如 5.1.2 节中所述，在生成过程中的每一步，都会选取词汇表中概率得分最高的 token 作为生成的 token。\n",
    "\n",
    "接下来介绍两种控制生成文本随机性和多样性的方法：`temperature scaling`和`top-k sampling`。\n"
   ],
   "id": "e513d39d70746b53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.3.1 Temperature scaling\n",
    "\n",
    "本节将介绍`temperature scaling`，这是一种在生成下一个词时加入概率选择的技术。\n",
    "\n",
    "之前，在 `generate_text_simple` 函数中，我们总是用 `torch.argmax` 选择概率最高的 token 作为下一个词，这也叫做贪心解码。为了生成更加多样化的文本，可以将 `argmax` 替换为一种从概率分布中进行采样的函数（这里，概率分布是指模型在每一步为每个词汇生成的概率得分）。\n",
    "\n",
    "为了用具体的例子说明概率采样，我们将简要讨论下一词生成过程，并用一个非常小的词汇表来进行示例演示："
   ],
   "id": "69e9da42788ab81f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:34.556375Z",
     "start_time": "2026-01-13T13:35:34.527799100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ],
   "id": "e384ced35fba3d69",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "接下来，假设给 LLM 一个初始上下文‘every effort moves you’，并生成下一个 token 的 logits 分数（如下所示）：",
   "id": "ee866980ab31b0a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:34.603008100Z",
     "start_time": "2026-01-13T13:35:34.566906400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ],
   "id": "13ece4b1ebf59f8a",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "接着在 `generate_text_simple` 函数中，通过 softmax 函数将 logits 转化为概率，并通过 argmax 函数得到生成的 token 的 ID，最后通过逆词汇表将其映射回文本（可以回顾上一章）：",
   "id": "e380f5f5b86ae9b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:34.651163700Z",
     "start_time": "2026-01-13T13:35:34.604006900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ],
   "id": "71d1f6c9779f829a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "由于第四个位置的 logit 值最大，相应地，Softmax 归一化后的概率分数也在该位置上最大，因此生成的下一个词就是这个位置对应的词。\n",
    "\n",
    "为了实现概率采样过程，现在可以用 PyTorch 中的 multinomial 函数代替 argmax："
   ],
   "id": "71fd627520231be2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:34.731294700Z",
     "start_time": "2026-01-13T13:35:34.656169600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ],
   "id": "db090c6fba413405",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "输出依然是“forward”，这和之前一样。这是为什么？ multinomial 函数根据每个 token 的概率得分来采样下一个 token。换句话说，“forward” 依然是最有可能的 token，因此大多数情况下会被 multinomial 选中，但并不是每次都选中。为了演示这一点，我们可以实现一个函数，重复采样 1000 次：",
   "id": "82775e94bcb07bcb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:34.836514200Z",
     "start_time": "2026-01-13T13:35:34.732301500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_sample_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1000)]\n",
    "    sample_ids =torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sample_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sample_tokens(probas)"
   ],
   "id": "7e6cdc7333c7047e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "采样输出结果如下：\n",
    "\n",
    "```\n",
    "73 x closer\n",
    "0 x every\n",
    "0 x effort\n",
    "582 x forward\n",
    "2 x inches\n",
    "0 x moves\n",
    "0 x pizza\n",
    "343 x toward\n",
    "```\n",
    "\n",
    "从输出结果可以看出，单词‘forward’在生成过程中被采样的次数最多（在 1000 次生成中出现了 582 次），但‘closer’、‘inches’和‘toward’等其他词语也偶尔会被采样到。这意味着，如果在生成函数 generate_and_print_sample 中将 argmax 替换为 multinomial，模型有时会生成类似‘every effort moves you toward’、‘every effort moves you inches’和‘every effort moves you closer’这样的句子，而不是固定生成‘every effort moves you forward’。\n",
    "\n",
    "我们可以通过一种称为`temperature scaling`的方法进一步控制分布和选择过程，所谓`temperature scaling`，其实就是将 logits 除以一个大于 0 的数：\n"
   ],
   "id": "15a2cf5b27c7ed23"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:35.825834800Z",
     "start_time": "2026-01-13T13:35:34.841038900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "#Temperatures greater than 1 result in more uniformly distributed token probabilities, and Temperatures smaller than 1 will result in more confident (sharper or more peaky) distributions. Let's illustrate this by plotting the original probabilities alongside probabilities scaled with different temperature values:\n",
    "temperatures = [1, 0.1, 5]             #A\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#A 原始、较低和较高置信度"
   ],
   "id": "1fd9d5b558e95e10",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "图 5.14 展示了生成的图表:\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.14.png\" width=\"75%\" />\n",
    "\n",
    "当 temperature 取 1 时，logits 在传递给 softmax 函数之前会除以 1，计算概率得分。这意味着，temperature 为 1 时相当于不进行任何缩放。在这种情况下，模型将根据原始的 softmax 概率，通过 PyTorch 中的`multinomial`函数来选择 token。\n",
    "\n",
    "如图 5.14 所示，当 temperature 设置为非常小的值（如 0.1）时，生成的分布会更加尖锐，因此`multinomial`函数几乎总是选择最可能的 token（这里是 ‘forward’），其行为接近 argmax 函数。相反，当 temperature 设置为 5 时，生成的分布更接近均匀分布，其他 token 被选中的频率更高。这种情况下，生成的文本多样性增加，但也更可能出现无意义的内容。例如，temperature 设置为 5 时，模型生成类似 ‘every effort moves you pizza’ 的文本概率大约为 4%。\n",
    "\n",
    "> [!TIP]\n",
    ">\n",
    "> **个人思考：** 为什么 temperature 值非常小时，生成的概率分布会更加尖锐，越大时，概率分布会更加均匀，文中只是说了结论，没有说过程。\n",
    ">\n",
    "> **temperature** 参数被引入到 softmax 函数中，用于缩放 logits，从而控制输出的概率分布。当引入 temperature 后，softmax 函数的公式变为：\n",
    ">\n",
    "> $$ P\\left(x_{i}\\right)=\\frac{\\exp \\left(\\frac{z_{i}}{T}\\right)}{\\sum_{j} \\exp \\left(\\frac{z_{j}}{T}\\right)} $$\n",
    ">\n",
    "> 1. **当 T>1**\n",
    ">    所有 logits 被除以 T，缩放后，差异变小。由于 exp 函数的敏感性较高，这意味着 logits 值的差异被“压平”，使得最优词的概率降低，而其他次优词的概率提高。输出的概率分布变得更加均匀，再结合multinomial函数，可以使生成结果更加多样化，但同时也降低了生成结果的确定性。\n",
    ">\n",
    "> 2. **当 T<1**\n",
    ">\n",
    ">    logits 除以 T 后会被放大，差异变得更加显著。softmax 函数会使最高 logit 对应的词语的概率变得更高，其他词语的概率更低。这导致输出的概率分布更加集中，模型更倾向于选择概率最大的词，从而提高了生成结果的确定性。\n"
   ],
   "id": "86497bd3180ac203"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.3.2 Top-k 采样\n",
    "\n",
    "在前一节中，我们实现了一种结合`temperature scaling`的概率采样方法来增加生成内容的多样性。我们发现，较高的 temperature 值会使下一词的概率分布更均匀，从而降低模型反复选择最可能词的概率，这样可以生成更多样化的内容，使生成过程探索那些概率较低但可能更有趣和创意的路径。不过，这种方法的一个缺点是，有时会导致生成语法不正确或完全不合逻辑的内容，比如 \"every effort moves you pizza\"。\n",
    "\n",
    "在本节中，我们引入了另一种称为`top-k 采样`的概念，当与概率采样和`temperature scaling`结合使用时，可以提升文本生成效果。\n",
    "\n",
    "在 top-k 采样中，我们可以将采样限制在最有可能的前 k 个 token 内，并通过将其他 token 的概率设为零，将它们排除在选择之外，如图 5.15 所示。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.15.png\" width=\"75%\" />\n",
    "\n",
    "如图 5.15 所示，将所有未选中的 logits 替换为负无穷（-inf），这样在计算 Softmax 时，非 top-k 的 token 的概率为 0，剩下的概率之和为 1。（细心的读者可能记得，我们在第 3 章的因果注意力模块中使用过这种掩码技巧。）\n",
    "\n",
    "接下来让我们通过代码实现 Figure 5.15 中描述的 top-k 过程，首先选出 logits 值最大的那些 token：\n"
   ],
   "id": "3d0bd73f59377257"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:35.885749900Z",
     "start_time": "2026-01-13T13:35:35.831208200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos =torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ],
   "id": "5cf96a7cb19edc29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
    "Top positions: tensor([3, 7, 0])\n",
    "```\n",
    "接下来，我们应用 PyTorch 的 where 函数，将非 top-3 的 token 的 logit 值设为负无穷大（-inf）："
   ],
   "id": "e5a8a26149c6d2c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:35.949195200Z",
     "start_time": "2026-01-13T13:35:35.893982600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],   #A\n",
    "    input=torch.tensor(float('-inf')),              #B\n",
    "    other=next_token_logits                         #C\n",
    ")\n",
    "print(new_logits)\n",
    "\n",
    "#A 识别出小于 top 3 最小值的 logits\n",
    "#B 将这些较小的 logits 赋值为负无穷大\n",
    "#C 保留所有其他 token 的原始 logits"
   ],
   "id": "51820fe26aba8edc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "执行代码，得到以下用于预测下一个 token 的 logits （在 9 个 token 的词汇表中）：\n",
    "```\n",
    "tensor([4.5100, -inf, -inf, 6.7500, -inf, -inf, -inf, 6.2800, -inf])\n",
    "```\n",
    "\n",
    "最后，应用 softmax 函数将其转化为下一词的概率分布："
   ],
   "id": "275419ea121f767e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:35.995366Z",
     "start_time": "2026-01-13T13:35:35.954208900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "topk_probas =torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ],
   "id": "dc76ca3e76a0aeae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "可以看到，通过 top-3 方法得到的结果是三个非零的概率得分：\n",
    "```\n",
    "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n",
    "```\n",
    "\n",
    "我们现在可以应用temperature scaling 和multinomial函数来进行概率采样，从这 3 个非零概率得分中选择下一个 token。在下一节中，我们将通过修改文本生成函数来实现此操作。"
   ],
   "id": "a5f4aee9edb3aa65"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.3.3 对文本生成函数进行调整\n",
    "前两节介绍了两种增加 LLM 生成文本多样性的概念：`temperature scaling`和`top-k` 采样。本节中，我们将这两个概念整合并加入到之前用于生成文本的`generate_simple`函数中，从而创建一个新的`generate`函数："
   ],
   "id": "99b82d3447e1144b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:36.036454100Z",
     "start_time": "2026-01-13T13:35:35.996364500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Listing 5.4 A modified text generation function with more diversity\n",
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=1.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):                             #A\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:                                   #B\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        if temperature > 0.0:                                       #C\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:                                                       #D\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:                                      #E\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "#A For循环与之前相同：获取logits，仅关注最后的时间步\n",
    "#B 在新步骤中，通过top-k采样过滤logits\n",
    "#C 在新步骤中应用temperature scaling\n",
    "#D 在未使用temperature scaling时，执行贪婪的下一个token选择\n",
    "#E 如果遇到序列结束token且指定了eos_id，则提前停止生成"
   ],
   "id": "46d317a12b84efb1",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "现在来看看这个新的`generate`函数的实际效果：",
   "id": "2f0f58eee67f78b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:36.700550700Z",
     "start_time": "2026-01-13T13:35:36.037967800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "9eb9ef138b8f301c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you stand to work on surprise, a one of us had gone with random-\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "生成的文本如下:\n",
    "\n",
    "```\n",
    "Output text:\n",
    "Every effort moves you stand to work on surprise, a one of us had gone with random-\n",
    "```\n",
    "\n",
    "正如我们所见，当前生成的文本与之前在 5.3 节开头用 generate_simple 函数生成的文本有很大不同（例如那句\"Every effort moves you know,\" was one of the axioms he laid...!\"），而后者是模型从训练集中记忆的一段话"
   ],
   "id": "2e927fcda209a905"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.4 在 PyTorch 中加载和保存模型权重\n",
    "\n",
    "在本章中，我们讨论了如何数值化评估训练进度，以及从零开始预训练 LLM。尽管模型和数据集都相对较小，这次练习依然展示了预训练 LLM 的高昂成本。因此，能够保存 LLM 以避免每次在新会话中使用时都重新训练显得尤为重要。\n",
    "\n",
    "如图 5.16 的章节概览所示，本节将介绍如何保存和加载预训练模型。然后，在接下来的部分中，我们将从 OpenAI 加载一个更强大的预训练 GPT 模型到我们的 GPTModel 实例中。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.16.png\" width=\"75%\" />\n",
    "\n",
    "幸运的是，保存 PyTorch 模型相对简单。推荐的做法是保存模型的 `state_dict`（状态字典），这是一个字典，用于将模型的每一层映射到其对应的参数上，可以通过 `torch.save` 函数来实现，代码如下所示："
   ],
   "id": "95f40cdc05b3c981"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:37.674062200Z",
     "start_time": "2026-01-13T13:35:36.705541400Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"model.pth\")",
   "id": "34e32896b5d722f",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在以上代码中，`model.pth`是用于保存 `state_dict` 的文件名。`.pth` 是 PyTorch 文件的惯用扩展名，但实际上也可以使用其他扩展名。\n",
    "\n",
    "使用 `state_dict` 保存模型权重后，可以将权重加载到新的 GPTModel 模型实例中，具体操作如下：\n"
   ],
   "id": "94ad211ad5e457b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:39.012675100Z",
     "start_time": "2026-01-13T13:35:37.675087200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()"
   ],
   "id": "76d5f95806c8caf9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "正如第 4 章所讨论的，dropout 通过在训练过程中随机“丢弃”某些神经元，以防止模型过拟合。然而，在推理阶段，我们不希望随机丢弃网络中学到的任何信息。通过使用 `model.eval()`，模型会切换到推理阶段的评估模式，从而禁用 dropout 层。\n",
    "\n",
    "如果计划稍后继续预训练模型（例如使用本章之前定义的 `train_model_simple` 函数），那么建议同时保存优化器状态。\n",
    "\n",
    "AdamW 等自适应优化器会为每个模型参数存储额外信息。AdamW 使用历史数据动态调整每个模型参数的学习率。没有这些信息时，优化器会重置，模型可能无法有效学习，甚至无法正确收敛，进而失去生成连贯文本的能力。可以使用 `torch.save` 保存模型和优化器的状态，方法如下："
   ],
   "id": "b1135f9c1af407bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:42.073592800Z",
     "start_time": "2026-01-13T13:35:39.014674900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ],
   "id": "47a6158650fa2efb",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "接下来，我们可以按以下步骤恢复模型和优化器的状态：首先通过 `torch.load` 加载保存的数据，然后使用 `load_state_dict` 方法恢复状态：",
   "id": "c5b09fbdef7ca644"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:45.328022300Z",
     "start_time": "2026-01-13T13:35:42.075592600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ],
   "id": "36ec130709b82361",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.5 从 OpenAI 加载预训练权重\n",
    "\n",
    "之前，我们为了教学目的，使用有限的数据集（包含一本短篇小说集）训练了一个小型 GPT-2 模型，这样可以专注于讲解 LLM 的基本原理，而无需耗费大量时间和计算资源。\n",
    "\n",
    "OpenAI 公开了 GPT-2 模型的权重，使我们不必投入数十万甚至数百万美元自行在大规模语料上重新训练模型。\n",
    "\n",
    "在本节的余下部分，我们将把这些权重加载到 GPTModel 类中，并利用该模型进行文本生成。这里的权重是指存储在 PyTorch 的 Linear 和 Embedding 层的 `.weight`属性中的权重参数（在训练模型时，我们可以通过`model.parameters() `访问这些权重）。\n",
    "\n",
    "在后续章节中，我们将复用这些预训练权重，对模型进行微调以用于文本分类任务，并遵循类似 ChatGPT 的指令。\n",
    "\n",
    "请注意，OpenAI 最初使用 TensorFlow 来保存 GPT-2 的权重，因此在 Python 中加载这些权重需要安装 TensorFlow。另外，以下代码将使用进度条工具 tqdm 来跟踪下载进度，也需要提前安装。\n",
    "\n",
    "请在终端中执行以下命令来安装所需的库：\n",
    "\n",
    "```\n",
    "pip install tensorflow>=2.15.0 tqdm>=4.66\n",
    "```"
   ],
   "id": "b8a2a29e80134d33"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "由于下载代码篇幅较长，主要是样板代码，因此本章不会浪费篇幅详细讨论。读者可以直接从本章的在线资源库下载 `gpt_download.py` 模块:",
   "id": "904a27748f83cf1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:35:46.153312300Z",
     "start_time": "2026-01-13T13:35:45.341115100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ],
   "id": "721e1505189661f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x20f4fc1aab0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "接下来，在将此文件下载到本地目录后，建议读者简单查看文件内容，确保文件已正确保存并包含有效的 Python 代码。\n",
    "\n",
    "我们现在可以从 `gpt_download.py` 文件中导入 `download_and_load_gpt2` 函数，从而将 GPT-2 的架构设置（settings）和权重参数（params）加载到 Python 会话中："
   ],
   "id": "2312bcc2d2677dce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:36:00.228871900Z",
     "start_time": "2026-01-13T13:35:46.183623400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params =download_and_load_gpt2(model_size='124M', models_dir=\"gpt2\")"
   ],
   "id": "e897a3896a493c41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "Executing the proceeding code downloads the following 7 files associated with the 124M\n",
    "parameter GPT-2 model:\n",
    "checkpoint: 100%|███████████████████████████| 77.0/77.0 [00:00<00:00, 63.9kiB/s]\n",
    "encoder.json: 100%|█████████████████████████| 1.04M/1.04M [00:00<00:00, 2.20MiB/s]\n",
    "hprams.json: 100%|██████████████████████████| 90.0/90.0 [00:00<00:00, 78.3kiB/s]\n",
    "model.ckpt.data-00000-of-00001: 100%|███████| 498M/498M [01:09<00:00, 7.16MiB/s]\n",
    "model.ckpt.index: 100%|█████████████████████| 5.21k/5.21k [00:00<00:00, 3.24MiB/s]\n",
    "model.ckpt.meta: 100%|██████████████████████| 471k/471k [00:00<00:00, 2.46MiB/s]\n",
    "vocab.bpe: 100%|████████████████████████████| 456k/456k [00:00<00:00, 1.70MiB/s]\n",
    "```\n",
    "代码执行完成后，查看 `settings` 和 `params` 的内容："
   ],
   "id": "e3e310c1fecad862"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:36:00.298030800Z",
     "start_time": "2026-01-13T13:36:00.243690700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ],
   "id": "abec15322efd1924",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "输出如下：\n",
    "\n",
    "```\n",
    "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
    "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
    "```\n",
    "\n",
    "`settings` 和 `params` 都是 Python 字典。`settings` 字典存储了 LLM 的架构设置，与我们之前手动定义的 `GPT_CONFIG_124M` 设置类似；`params` 字典则包含实际的权重张量。注意，我们只打印了字典的键，因为打印整个权重内容会占用太多屏幕空间。不过，我们可以通过`print(params)` 打印整个字典，或使用特定的字典键选择对应张量进行查看，例如嵌入层的权重："
   ],
   "id": "e2b68068c155299c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:36:00.349734600Z",
     "start_time": "2026-01-13T13:36:00.302571100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ],
   "id": "5a316612a82600c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "token 嵌入层的权重如下所示：\n",
    "\n",
    "```\n",
    "[[-0.11010301 ... -0.1363697 0.01506208 0.04531523]\n",
    " [ 0.04034033 ... 0.08605453 0.00253983 0.04318958]\n",
    " [-0.12746179 ... 0.08991534 -0.12972379 -0.08785918]\n",
    " ...\n",
    " [-0.04453601 ... 0.10435229 0.09783269 -0.06952604]\n",
    " [ 0.1860082 ... -0.09625227 0.07847701 -0.02245961]\n",
    " [ 0.05135201 ... 0.00704835 0.15519823 0.12067825]]\n",
    "Token embedding weight tensor dimensions: (50257, 768)\n",
    "```\n",
    "\n",
    "我们通过 `download_and_load_gpt2(model_size=\"124M\", ...)` 加载了最小的 GPT-2 模型权重。此外，OpenAI 还提供了更大规模模型的权重，包括 \"355M\"、\"774M\" 和 \"1558M\" 等。尽管模型规模不同，但其整体架构是相同的，如图 5.17 所示。\n",
    "\n",
    "<img src=\"../images/chapter5/figure5.17.png\" width=\"75%\" />\n",
    "\n",
    "如图 5.17 所示，不同大小的 GPT-2 模型在总体架构上保持一致，但注意力头和 Transformer 模块等组件的重复次数以及嵌入维度大小有所不同。本章的剩余代码也会兼容这些更大的模型。\n",
    "\n",
    "在将 GPT-2 模型的权重加载到 Python 后，我们还需要将这些权重从 `settings` 和 `params` 字典转移到 GPTModel 实例中：\n"
   ],
   "id": "615a6f98dd478694"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:36:00.387599100Z",
     "start_time": "2026-01-13T13:36:00.357737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First, we create a dictionary that lists the differences between the different GPT model sizes, as explained in Figure 5.17:\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "# Suppose we are interested in loading the smallest model, \"gpt2-small (124M)\". We can use the corresponding settings from the model_configs table able to update our full-length GPT_CONFIG_124M we defined and used earlier throughout the chapter as follows:\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ],
   "id": "982dffc308f80ead",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "细心的读者可能记得，我们之前设置的 token 长度是 256，但 OpenAI 的原始 GPT-2 模型使用的是 1,024 的 token 长度，因此我们需要相应地更新 NEW_CONFIG:",
   "id": "2f2b8eab052a2550"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:46:10.282031400Z",
     "start_time": "2026-01-13T13:46:10.265875600Z"
    }
   },
   "cell_type": "code",
   "source": "NEW_CONFIG.update({\"context_length\": 1024})",
   "id": "297f22fd94ace593",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "此外，OpenAI 在多头注意力模块的线性层中使用了偏置向量，以实现查询（query）、键（key）和值（value）矩阵的计算。偏置向量在现代 LLM 中已不再常用，因为它们对提升模型性能没有帮助，因而不再必要。然而，由于我们使用的是预训练权重，为了保持一致性，仍需启用这些偏置向量：",
   "id": "1e6a2f90a8ccf19f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:46:12.897052100Z",
     "start_time": "2026-01-13T13:46:11.814556600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NEW_CONFIG.update({\"qkv_bias\": True})\n",
    "# We can now use the updated NEW_CONFIG dictionary to initialize a new GPTModel instance:\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ],
   "id": "fb63f81c57e99c00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "默认情况下，GPTModel 实例会使用随机权重进行预训练。而使用 OpenAI 的模型权重的最后一步是将 `params` 字典中加载的权重覆盖这些随机权重。\n",
    "\n",
    "为此，我们首先来定义一个简单的`assign`工具函数，用于检查两个张量或数组（左侧和右侧）的维度或形状是否一致，并将右侧张量作为可训练的 PyTorch 参数返回："
   ],
   "id": "608c4107b992e0e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:46:17.044758800Z",
     "start_time": "2026-01-13T13:46:17.017011300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ],
   "id": "b57a5c6cea7c158a",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "接下来，我们定义一个名为 `load_weights_into_gpt` 的函数，用于将 params 字典中的权重加载到 GPT 模型实例中：",
   "id": "7f95cad2c88e844e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:46:19.846144900Z",
     "start_time": "2026-01-13T13:46:19.784019900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Listing 5.5 Loading OpenAI weights into our GPT model code\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])               #A\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    for b in range(len(params[\"blocks\"])):                                       #B\n",
    "        q_w, k_w, v_w = np.split(                                                #C\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])                   #D\n",
    "\n",
    "\n",
    "#A 将模型的位置嵌入和token 嵌入的权重设置为 params 中指定的值\n",
    "#B 遍历模型中的每个 Transformer 模块\n",
    "#C 使用 np.split 函数将注意力和偏置权重分为三等份，分别用于查询、键和值组件\n",
    "#D OpenAI 的原始 GPT-2 模型在输出层中复用了 token 嵌入的权重，以减少参数总量，这一概念称为权重共享"
   ],
   "id": "4bed50c1fd84c49f",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在 `load_weights_into_gpt` 函数中，我们需要将 OpenAI 实现中的权重与自定义的 GPTModel 实现进行精确匹配。举个例子，OpenAI 将第一个 Transformer 模块的输出投影层权重存储在 `params[\"blocks\"][0][\"attn\"][\"c_proj\"][\"w\"]` 中。而在我们的实现中，这个权重对应于 `gpt.trf_blocks[b].att.out_proj.weight`，其中 `gpt` 是一个 GPTModel 实例。\n",
    "\n",
    "在开发 `load_weights_into_gpt` 函数时，由于 OpenAI 的命名规范和我们的略有不同，我们进行了大量的尝试。幸运的是，`assign` 函数会在张量维度不匹配时发出警告。此外，如果这个函数有错误，我们会发现生成的 GPT 模型无法生成连贯的文本，从而识别出问题。\n",
    "\n",
    "我们暂时不在实际操作中尝试 `load_weights_into_gpt`，而是直接将 OpenAI 模型的权重加载到我们自己的 `GPTModel` 实例 `gpt` 中：\n"
   ],
   "id": "708e268d2ec20537"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:46:22.986196Z",
     "start_time": "2026-01-13T13:46:22.712617500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ],
   "id": "ef6187121db1ad0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "如果模型加载成功，就可以使用之前的 `generate` 函数生成新文本：",
   "id": "5744529b0aa1c310"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T13:49:45.526989900Z",
     "start_time": "2026-01-13T13:49:44.095491300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "eadfd1764af426e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "生成的文本如下：\n",
    "\n",
    "```\n",
    "Output text:\n",
    " Every effort moves you toward finding an ideal new way to practice something!\n",
    "What makes us want to be on top of that?\n",
    "```\n",
    "\n",
    "我们可以确认模型权重已正确加载，因为模型能够生成连贯的文本；在这个过程中，哪怕一个小错误都会导致模型生成失败。\n",
    "\n",
    "在接下来的章节中，我们将进一步使用该预训练模型，并对其进行微调，使其能够进行文本分类和指令执行。\n"
   ],
   "id": "9de75b2a750ecc32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.6 本章摘要\n",
    "\n",
    "+ 大语言模型在生成文本时，逐个生成 token。\n",
    "+ 默认情况下，模型通过将输出转换为概率分数，并选择其中概率最高的 token 来生成下一个 token，这种方式称为“贪心解码”。\n",
    "+ 通过概率采样和`temperature scaling`，可以影响生成文本的多样性和连贯性。\n",
    "+ 训练集和验证集的损失可以用来评估 LLM 在训练过程中生成文本的质量。\n",
    "+ 预训练 LLM 的过程就是通过调整模型权重来最小化训练损失。\n",
    "+ LLM 的训练循环是深度学习中的标准流程，通常使用交叉熵损失和 AdamW 优化器。\n",
    "+ 在大规模文本数据集上预训练 LLM 非常耗费时间和资源，因此可以加载 OpenAI 提供的开源预训练权重，作为自行预训练模型的替代方案。"
   ],
   "id": "236d5e25a00a39"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
